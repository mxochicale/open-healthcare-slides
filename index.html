<!DOCTYPE html>
<html lang="en"><head>
<link href="./favicon.svg" rel="icon" type="image/svg+xml">
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b53751a350365c71b6c909e95f209ed1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <title>index</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #f8f8f2;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #f8f8f2; } /* Normal */
    code span.al { color: #f07178; background-color: #2a0f15; font-weight: bold; } /* Alert */
    code span.an { color: #d4d0ab; } /* Annotation */
    code span.at { color: #00e0e0; } /* Attribute */
    code span.bn { color: #d4d0ab; } /* BaseN */
    code span.bu { color: #abe338; } /* BuiltIn */
    code span.cf { color: #ffa07a; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #abe338; } /* Char */
    code span.cn { color: #ffd700; } /* Constant */
    code span.co { color: #f8f8f2; font-style: italic; } /* Comment */
    code span.cv { color: #ffd700; } /* CommentVar */
    code span.do { color: #f8f8f2; } /* Documentation */
    code span.dt { color: #ffa07a; } /* DataType */
    code span.dv { color: #d4d0ab; } /* DecVal */
    code span.er { color: #f07178; text-decoration: underline; } /* Error */
    code span.ex { color: #00e0e0; font-weight: bold; } /* Extension */
    code span.fl { color: #d4d0ab; } /* Float */
    code span.fu { color: #ffa07a; } /* Function */
    code span.im { color: #abe338; } /* Import */
    code span.in { color: #d4d0ab; } /* Information */
    code span.kw { color: #ffa07a; font-weight: bold; } /* Keyword */
    code span.op { color: #ffa07a; } /* Operator */
    code span.ot { color: #00e0e0; } /* Other */
    code span.pp { color: #dcc6e0; } /* Preprocessor */
    code span.re { color: #00e0e0; background-color: #f8f8f2; } /* RegionMarker */
    code span.sc { color: #abe338; } /* SpecialChar */
    code span.ss { color: #abe338; } /* SpecialString */
    code span.st { color: #abe338; } /* String */
    code span.va { color: #00e0e0; } /* Variable */
    code span.vs { color: #abe338; } /* VerbatimString */
    code span.wa { color: #dcc6e0; } /* Warning */
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-949fcd71989a651394be00d684876026.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="">
<meta property="og:description" content="">
<meta property="og:image" content="https://mxochicale.github.io/open-healthcare-slides/favicon.svg">
<meta name="twitter:title" content="">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://mxochicale.github.io/open-healthcare-slides/favicon.svg">
<meta name="twitter:creator" content="@mxochicale">
<meta name="twitter:card" content="summary">
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">


<section id="section" class="title-slide slide level1 centeredslide center" data-background-iframe="https://saforem2.github.io/grid-worms-animation/" loading="lazy">
<h1></h1>
<div style="background-color: rgba(22,22,22,0.75); border-radius: 10px; text-align:center; padding: 0px; padding-left: 1.5em; padding-right: 1.5em; max-width: min-content; min-width: max-content; margin-left: auto; margin-right: auto; padding-top: 0.2em; padding-bottom: 0.2em; line-height: 1.5em!important;">
<p><span style="color:#939393; font-size:1.5em; font-weight: bold;">How Open-Source Software is</span><br>
<span style="color:#939393; font-size:1.5em; font-weight: bold;">Shapping the Future of Healthcare?</span></p>
<p><span style="padding-bottom: 0.5rem;"><br>&nbsp;</span><br>
<a href="http://mxochicale.github.io/"><i class="fa-solid fa-home"></i></a> Miguel Xochicale, Sr-RSE@ARC-UCL<br>
<span style="font-size:0.8em;"><span style="border-bottom: 0.5px solid #00ccff;"><a href="https://github.com/mxochicale/"><i class="fa-brands fa-github"></i> <code>mxochicale/</code></a></span><span style="border-bottom: 0.5px solid #00ccff;"><a href="https://github.com/mxochicale/open-healthcare-slides"><code>open-healthcare-slides</code></a></span></span></p>
</div>
<div class="footer">
<p><span class="dim-text" style="&quot;text-align:left;'">7-March-2025; Guest lecture at University of Bristol <a href="https://github.com/saforem2/grid-worms-animation/">(grid-worms-animation 2023 by saforem2)</a></span></p>
</div>
</section>

<section>
<section id="overview" class="title-slide slide level1 center" style="font-size: 90%;">
<h1>Overview</h1>
<ul>
<li><a href="#/sec-b2b">From bench to bedside</a></li>
<li>Few use cases
<ul>
<li><a href="#/sec-fus">Fetal Ultrasound Image Synthesis</a></li>
<li><a href="#/sec-rtai">Real-time AI diagnosis</a> <!--  * [Endoscopy-based video](#sec-ps) --> <!--  * [Eye movement disorders](#sec-ed) --></li>
</ul></li>
<li><a href="#/sec-ossh">Open-Source Software in Healthcare</a></li>
<li><a href="#/sec-ta">Takeaways</a></li>
</ul>
</section>
<section id="about-me" class="slide level2">
<h2>About me</h2>
<div id="sec-mt" style="margin-top: 0px; font-size: 50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/mx.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</section></section>
<section>
<section id="sec-b2b" class="title-slide slide level1 center">
<h1><span class="emoji" data-emoji="wrench">🔧</span> <span class="emoji" data-emoji="hospital">🏥</span> From bench to bedside</h1>

</section>
<section id="innovation-regulation-in-surgmedai-tech" class="slide level2">
<h2>Innovation &amp; regulation in Surg/Med/AI Tech <!-- ST - i'd argue that good regulation is a key driver of innovation. Without regulation you just have a bunch of people doing stuff they like, whereas with regulation you can drive innovation to achieve good societal impacts. So it's not one vs the other --></h2>
<div style="margin-top: 0px; font-size: 50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/regulation-innovation/balance-between-regulation-innovation.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</section>
<section id="challenges-in-the-ai-clinical-translation" class="slide level2">
<h2><span class="emoji" data-emoji="hospital">🏥</span> Challenges in the AI clinical translation</h2>

<img data-src="figures/regulation-innovation/li2023-fig3.svg" class="quarto-figure quarto-figure-center r-stretch" style="width:100.0%" id="fig-template"><p class="caption">
Figure&nbsp;1: Medical AI translational challenges between system development and routine clinical application
</p><div style="font-size: 40%;">
<p>Li, Zhongwen, Lei Wang, Xuefang Wu, Jiewei Jiang, Wei Qiang, He Xie, Hongjian Zhou, Shanjun Wu, Yi Shao, and Wei Chen. “Artificial intelligence in ophthalmology: The path to the real-world clinic.” Cell Reports Medicine 4, no. 7 (2023).</p>
</div>
<aside class="notes">
<p><span class="emoji" data-emoji="wrench">🔧</span> <span class="emoji" data-emoji="recycle">♻️</span> <span class="emoji" data-emoji="hospital">🏥</span> Software as a Medical Device (SaMD)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="iec-62304-standard-for-software" class="slide level2">
<h2>IEC 62304 standard for software</h2>
<div style="margin-top: 0px; font-size: 50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/regulation-innovation/iec62304.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 30%;">
<p>https://www.iso.org/standard/38421.html</p>
</div>
</section>
<section id="good-ml-practices-by-fda" class="slide level2">
<h2>Good ML practices by FDA</h2>
<div style="margin-top: 0px; font-size: 50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/regulation-innovation/goodALMLFDA.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 30%;">
<p>US-FDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper: https://www.fda.gov/files/medical%20devices/published/US-FDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper.pdf</p>
</div>
<aside class="notes">
<p>Regulatory Framework for Modifications to (AI/ML)-Based Software as a Medical Device (SaMD)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="isoiec-quality-standards-in-the-ai-landscape" class="slide level2">
<h2>ISO/IEC quality standards in the AI landscape</h2>

<img data-src="figures/regulation-innovation/ai-standarization-landscape.svg" class="quarto-figure quarto-figure-center r-stretch" style="width:100.0%" id="fig-template"><p class="caption">
Figure&nbsp;2: AI standarisation landscape
</p><div style="font-size: 30%;">
<p>Janaćković, G., Vasović, D. and Vasović, B., 2024. ARTIFICIAL INTELLIGENCE STANDARDISATION EFFORTS. ENGINEERING MANAGEMENT AND COMPETITIVENESS (EMC 2024), p.250.<br>
Oviedo, Jesús, Moisés Rodriguez, Andrea Trenta, Dino Cannas, Domenico Natale, and Mario Piattini. “ISO/IEC quality standards for AI engineering.” Computer Science Review 54 (2024): 100681.</p>
</div>
</section></section>
<section>
<section id="use-case" class="title-slide slide level1 center">
<h1>Use case</h1>
<p>Fetal Ultrasound Image Synthesis <!-- this section (up to slide 25) seems very sciency and not very open - source softwarey. i.e. theres a lot of experiments and results, but it doesn't seem to be about open source software until you get to the last slide (xfetus). I think the audience at FOSDEM will be more interested in the software than the application. Can you simplify the science and significantly expand on the software? --></p>
</section>
<section id="dating-ultrasound-scan-12-week-scan" class="slide level2">
<h2>Dating Ultrasound Scan (12 week scan)</h2>
<div style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/12-week-scan.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>Wright-Gilbertson M. 2014 in PhD thesis; https://en.wikipedia.org/wiki/Gestational_age; National-Health-Service 2021. Screening for down’s syndrome, edwards’ syndrome and patau’s syndrome. https://www.nhs.uk/pregnancy/your- pregnancy- care</p>
</div>
</section>
<section id="challenges-of-us-biometric-measurements" class="slide level2">
<h2>Challenges of US biometric measurements</h2>
<ul>
<li>Operator dependant,</li>
<li>Clinical system dependant,</li>
<li>Fetal position,</li>
<li>Similar morphological and echogenic characteristics in the US,</li>
<li><strong>Few public datasets are available (we have only found three)</strong>
<ul>
<li>Data masking: Anonymisation or pseudonymisation?</li>
<li>Personal Data Protection Policy</li>
</ul></li>
</ul>
<div style="font-size: 40%;">
<p>Sciortino et al.&nbsp;in Computers in Biology and Medicine 2017 https://doi.org/10.1016/j.compbiomed.2017.01.008; He et al.&nbsp;in Front. Med. 2021 https://doi.org/10.3389/fmed.2021.729978</p>
</div>
</section>
<section id="research-questions" class="slide level2">
<h2>Research Questions</h2>
<ul>
<li>Research and implement deep learning methods for generating synthetic fetal ultrasound images for both normal and abnormal cases,</li>
<li>Propose and apply methods to evaluate quantitative and qualitative images of fetal us image synthesis.</li>
</ul>
</section>
<section id="transthalamic" class="slide level2">
<h2>TransThalamic</h2>
<p>Fetal Brain Ultrasound Image Dataset</p>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/fetal-planes-dataset-TransThalami.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>Burgos-Artizzu, X et al.&nbsp;(2020). FETAL PLANES DB: Common maternal-fetal ultrasound images [Data set]. In Nature Scientific Reports (1.0, Vol. 10, p.&nbsp;10200). Zenodo. https://doi.org/10.5281/zenodo.3904280</p>
</div>
</section>
<section id="transcerebellum-plain" class="slide level2">
<h2>TransCerebellum Plain</h2>
<p>Fetal Brain Ultrasound Image Dataset</p>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/fetal-planes-dataset-TransCerebellum.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>Burgos-Artizzu, X et al.&nbsp;(2020). FETAL PLANES DB: Common maternal-fetal ultrasound images [Data set]. In Nature Scientific Reports (1.0, Vol. 10, p.&nbsp;10200). Zenodo. https://doi.org/10.5281/zenodo.3904280</p>
</div>
</section>
<section id="transventricular-plane" class="slide level2">
<h2>TransVentricular Plane</h2>
<p>Fetal Brain Ultrasound Image Dataset</p>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/fetal-planes-dataset-TransVentricular.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>Burgos-Artizzu, X et al.&nbsp;(2020). FETAL PLANES DB: Common maternal-fetal ultrasound images [Data set]. In Nature Scientific Reports (1.0, Vol. 10, p.&nbsp;10200). Zenodo. https://doi.org/10.5281/zenodo.3904280</p>
</div>
</section>
<section id="aiml-pipeline" class="slide level2">
<h2>AI/ML pipeline</h2>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/ai-pipeline-gans-based-pipeline-fetal-imaging.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</section>
<section id="methods" class="slide level2">
<h2>Methods</h2>
<p>GAN-based fetal imaging</p>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/gan-based-fetal-imaging.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<ol type="a">
<li>Bautista et al.&nbsp;2022, ”Empirical Study of Quality Image Assessment for Synthesis of Fetal Head Ultrasound Imaging with DCGANs” MIUA https://github.com/xfetus/miua2022 (b) Liu et al.&nbsp;2021 ”Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis” https://arxiv.org/abs/2101.04775</li>
</ol>
</div>
</section>
<section id="methods-1" class="slide level2">
<h2>Methods</h2>
<!-- ST: this slide has a lot of copy paste text. Are you expecting the audience to read or understand it. What's the message you want to communicate here -->
<p>Diffusion-Super-Resolution-GAN (DSR-GAN) Transformer-based-GAN</p>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/methods-diffusion-Super-Resolution-GAN-transformer-based-GAN.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>M. Iskandar et al.&nbsp;“Towards Realistic Ultrasound Fetal Brain Imaging Synthesis” in MIDL2023. https://github.com/xfetus/midl2023</p>
</div>
</section>
<section id="image-quality-assessment" class="slide level2">
<h2>Image Quality Assessment</h2>
<p>Quaility of synthesised images are evaluated with Frechet inception distance (FID), measuring the distance between distributions of synthetised and original images (Heusel et al., 2017).</p>
<p>The lower the FID number is, the more similar the synthetised images are to the original ones. FID metric showed to work well with fetal head US compared to other metrics (Bautista et al., 2012).</p>
<div style="font-size: 40%;">
<p>M. Iskandar et al.&nbsp;“Towards Realistic Ultrasound Fetal Brain Imaging Synthesis” in MIDL2023. https://github.com/xfetus/midl2023</p>
</div>
</section>
<section id="experiments-design-and-results" class="slide level2">
<h2>Experiments: Design and results</h2>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/results-only-images.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>M. Iskandar et al.&nbsp;“Towards Realistic Ultrasound Fetal Brain Imaging Synthesis” in MIDL2023. https://github.com/xfetus/midl2023</p>
</div>
</section>
<section id="experiments-design-and-results-1" class="slide level2">
<h2>Experiments: Design and results</h2>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/results-plots.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>M. Iskandar et al.&nbsp;“Towards Realistic Ultrasound Fetal Brain Imaging Synthesis” in MIDL2023. https://github.com/xfetus/midl2023</p>
</div>
</section>
<section id="fetal-us-imaging-with-diffusion-models" class="slide level2">
<h2>Fetal US imaging with Diffusion models</h2>
<div id="sec-hp" style="margin-top: 0px; font-size: 50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/diffusion-based-generative-model.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<ol type="a">
<li>Ho et al.&nbsp;2020 ”Denoising Diffusion Probabilistic Models” https://arxiv.org/abs/2006.11239</li>
<li>Fiorentino et al.&nbsp;2022 ”A Review on Deep Learning Algorithms for Fetal Ultrasound-Image Analysis” https://arxiv.org/abs/2201.12260</li>
</ol>
</div>
</section>
<section id="github.comxfetusmidl2023" class="slide level2">
<h2><i class="fa-brands fa-github"></i> github.com/xfetus/midl2023</h2>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/github-repository.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>M. Iskandar et al.&nbsp;“Towards Realistic Ultrasound Fetal Brain Imaging Synthesis” in MIDL2023. <i class="fa-brands fa-github"></i> <a href="https://github.com/xfetus/midl2023">https://github.com/xfetus/midl2023</a></p>
</div>
</section>
<section id="xfetus" class="slide level2">
<h2>xfetus <span class="emoji" data-emoji="baby">👶</span> <span class="emoji" data-emoji="brain">🧠</span> <span class="emoji" data-emoji="robot">🤖</span></h2>
<p>A Python-based library for synthesising ultrasound images of fetal development</p>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/fetal-ultrasound-image-synthesis/xfetus-project.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<p><i class="fa-brands fa-github"></i> <a href="https://github.com/xfetus/xfetus">https://github.com/xfetus/xfetus</a></p>
<aside class="notes">
<p>TODO: * Resolve PRs https://github.com/xfetus/xfetus/pulls * Show emojis in the main README</p>
<p>A library for ultrasound fetal imaging synthesis using:</p>
<ul>
<li>GANs,<br>
</li>
<li>transformers, and<br>
</li>
<li>diffusion models.</li>
</ul>
<div style="font-size: 50%;">
<p><i class="fa-brands fa-github"></i> <a href="https://github.com/xfetus/xfetus">https://github.com/xfetus/xfetus</a></p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="use-case-1" class="title-slide slide level1 center">
<h1>Use case</h1>
<p><span class="emoji" data-emoji="wrench">🔧</span> Developing real-time AI applications for diagnosis <!-- can you expand on the open source ecosystem around Holoscan here? 
Do you have any videos or results you could show for real time diagnoses?
--></p>
</section>
<section id="real-time-ai-applications-for-surgery" class="slide level2">
<h2>Real-time AI Applications for Surgery</h2>

<img data-src="figures/holoscan-platform/rtai4spipeline.svg" class="quarto-figure quarto-figure-center r-stretch" style="width:100.0%" id="fig-template"><p class="caption">
Figure&nbsp;3: Development and deployment pipeline for real-time AI apps for surgery
</p><aside class="notes">
<p>Pipeline with development and deployment of real-time AI apps for surgery</p>
<p>{fig-align=center} {fig-pos=‘b’} b(bottom) h(here) p(page) t(top)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nvidia-holoscan-platform" class="slide level2">
<h2>NVIDIA Holoscan platform</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Holoscan-SDK</p>
<p><img data-src="figures/holoscan-platform/holohub.svg"></p>
<p><a href="https://github.com/nvidia-holoscan/holoscan-sdk/tree/main"><i class="fa-brands fa-github"></i> <code>holoscan-sdk</code></a></p>
<p><a href="https://github.com/nvidia-holoscan/holohub"><i class="fa-brands fa-github"></i> <code>holohub</code></a></p>
</div><div class="column" style="width:50%;">
<p>Clara-AGX</p>
<p><img data-src="figures/holoscan-platform/clara_agx_dev_kit_components.svg"></p>
<p><a href="https://github.com/nvidia-holoscan/holoscan-docs/blob/main/devkits/clara-agx/clara_agx_user_guide.md"><i class="fa-brands fa-github"></i> <code>Clara-AGX DevKit</code></a></p>
<p><a href="https://github.com/nvidia-holoscan/holoscan-docs/blob/main/devkits/nvidia-igx-orin/nvidia_igx_orin_user_guide.md"><i class="fa-brands fa-github"></i> <code>Orin-IGX DevKit</code></a></p>
</div></div>
<aside class="notes">
<p>Holoscan platform</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="holoscan-core-concepts" class="slide level2">
<h2>Holoscan Core Concepts</h2>

<img data-src="figures/holoscan-platform/holoscan_core_concepts.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-template"><p class="caption">
Figure&nbsp;4: Operator: An operator is the most basic unit of work in this framework.
</p><aside class="notes">
<p>https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="bring-your-own-model-byom" class="slide level2 scrollable">
<h2>Bring Your Own Model (BYOM)</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Workflow</a></li><li><a href="#tabset-1-2">Python</a></li><li><a href="#tabset-1-3">YAML</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<div id="fig-template" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-template-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="figures/holoscan-platform/byom.svg" class="quarto-figure quarto-figure-center">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-template-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Connecting Operators
</figcaption>
</figure>
</div>
</div>
<div id="tabset-1-2">
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> os</span>
<span id="cb1-2"><a></a><span class="im">from</span> argparse <span class="im">import</span> ArgumentParser</span>
<span id="cb1-3"><a></a></span>
<span id="cb1-4"><a></a><span class="im">from</span> holoscan.core <span class="im">import</span> Application</span>
<span id="cb1-5"><a></a></span>
<span id="cb1-6"><a></a><span class="im">from</span> holoscan.operators <span class="im">import</span> (</span>
<span id="cb1-7"><a></a>    FormatConverterOp,</span>
<span id="cb1-8"><a></a>    HolovizOp,</span>
<span id="cb1-9"><a></a>    InferenceOp,</span>
<span id="cb1-10"><a></a>    SegmentationPostprocessorOp,</span>
<span id="cb1-11"><a></a>    VideoStreamReplayerOp,</span>
<span id="cb1-12"><a></a>)</span>
<span id="cb1-13"><a></a><span class="im">from</span> holoscan.resources <span class="im">import</span> UnboundedAllocator</span>
<span id="cb1-14"><a></a></span>
<span id="cb1-15"><a></a></span>
<span id="cb1-16"><a></a><span class="kw">class</span> BYOMApp(Application):</span>
<span id="cb1-17"><a></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data):</span>
<span id="cb1-18"><a></a>        <span class="co">"""Initialize the application</span></span>
<span id="cb1-19"><a></a></span>
<span id="cb1-20"><a></a><span class="co">Parameters</span></span>
<span id="cb1-21"><a></a><span class="co">----------</span></span>
<span id="cb1-22"><a></a><span class="co">data : Location to the data</span></span>
<span id="cb1-23"><a></a><span class="co">"""</span></span>
<span id="cb1-24"><a></a></span>
<span id="cb1-25"><a></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-26"><a></a></span>
<span id="cb1-27"><a></a>        <span class="co"># set name</span></span>
<span id="cb1-28"><a></a>        <span class="va">self</span>.name <span class="op">=</span> <span class="st">"BYOM App"</span></span>
<span id="cb1-29"><a></a></span>
<span id="cb1-30"><a></a>        <span class="cf">if</span> data <span class="op">==</span> <span class="st">"none"</span>:</span>
<span id="cb1-31"><a></a>            data <span class="op">=</span> os.environ.get(<span class="st">"HOLOSCAN_INPUT_PATH"</span>, <span class="st">"../data"</span>)</span>
<span id="cb1-32"><a></a></span>
<span id="cb1-33"><a></a>        <span class="va">self</span>.sample_data_path <span class="op">=</span> data</span>
<span id="cb1-34"><a></a></span>
<span id="cb1-35"><a></a>        <span class="va">self</span>.model_path <span class="op">=</span> os.path.join(os.path.dirname(<span class="va">__file__</span>), <span class="st">"../model"</span>)</span>
<span id="cb1-36"><a></a>        <span class="va">self</span>.model_path_map <span class="op">=</span> {</span>
<span id="cb1-37"><a></a>            <span class="st">"byom_model"</span>: os.path.join(<span class="va">self</span>.model_path, <span class="st">"identity_model.onnx"</span>),</span>
<span id="cb1-38"><a></a>        }</span>
<span id="cb1-39"><a></a></span>
<span id="cb1-40"><a></a>        <span class="va">self</span>.video_dir <span class="op">=</span> os.path.join(<span class="va">self</span>.sample_data_path, <span class="st">"racerx"</span>)</span>
<span id="cb1-41"><a></a>        <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="va">self</span>.video_dir):</span>
<span id="cb1-42"><a></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Could not find video data:</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>video_dir<span class="op">=</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-43"><a></a></span>
<span id="cb1-44"><a></a><span class="co"># Define the workflow</span></span>
<span id="cb1-45"><a></a>        <span class="va">self</span>.add_flow(source, viz, {(<span class="st">"output"</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb1-46"><a></a>        <span class="va">self</span>.add_flow(source, preprocessor, {(<span class="st">"output"</span>, <span class="st">"source_video"</span>)})</span>
<span id="cb1-47"><a></a>        <span class="va">self</span>.add_flow(preprocessor, inference, {(<span class="st">"tensor"</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb1-48"><a></a>        <span class="va">self</span>.add_flow(inference, postprocessor, {(<span class="st">"transmitter"</span>, <span class="st">"in_tensor"</span>)})</span>
<span id="cb1-49"><a></a>        <span class="va">self</span>.add_flow(postprocessor, viz, {(<span class="st">"out_tensor"</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb1-50"><a></a></span>
<span id="cb1-51"><a></a></span>
<span id="cb1-52"><a></a><span class="kw">def</span> main(config_file, data):</span>
<span id="cb1-53"><a></a>    app <span class="op">=</span> BYOMApp(data<span class="op">=</span>data)</span>
<span id="cb1-54"><a></a>    <span class="co"># if the --config command line argument was provided, it will override this config_file</span></span>
<span id="cb1-55"><a></a>    app.config(config_file)</span>
<span id="cb1-56"><a></a>    app.run()</span>
<span id="cb1-57"><a></a></span>
<span id="cb1-58"><a></a></span>
<span id="cb1-59"><a></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb1-60"><a></a>    <span class="co"># Parse args</span></span>
<span id="cb1-61"><a></a>    parser <span class="op">=</span> ArgumentParser(description<span class="op">=</span><span class="st">"BYOM demo application."</span>)</span>
<span id="cb1-62"><a></a>    parser.add_argument(</span>
<span id="cb1-63"><a></a>        <span class="st">"-d"</span>,</span>
<span id="cb1-64"><a></a>        <span class="st">"--data"</span>,</span>
<span id="cb1-65"><a></a>        default<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb1-66"><a></a>        <span class="bu">help</span><span class="op">=</span>(<span class="st">"Set the data path"</span>),</span>
<span id="cb1-67"><a></a>    )</span>
<span id="cb1-68"><a></a></span>
<span id="cb1-69"><a></a>    args <span class="op">=</span> parser.parse_args()</span>
<span id="cb1-70"><a></a>    config_file <span class="op">=</span> os.path.join(os.path.dirname(<span class="va">__file__</span>), <span class="st">"byom.yaml"</span>)</span>
<span id="cb1-71"><a></a>    main(config_file<span class="op">=</span>config_file, data<span class="op">=</span>args.data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-3">
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="op">%</span>YAML <span class="fl">1.2</span></span>
<span id="cb2-2"><a></a>replayer:  <span class="co"># VideoStreamReplayer</span></span>
<span id="cb2-3"><a></a>  basename: <span class="st">"racerx"</span></span>
<span id="cb2-4"><a></a>  frame_rate: <span class="dv">0</span> <span class="co"># as specified in timestamps</span></span>
<span id="cb2-5"><a></a>  repeat: true <span class="co"># default: false</span></span>
<span id="cb2-6"><a></a>  realtime: true <span class="co"># default: true</span></span>
<span id="cb2-7"><a></a>  count: <span class="dv">0</span> <span class="co"># default: 0 (no frame count restriction)</span></span>
<span id="cb2-8"><a></a></span>
<span id="cb2-9"><a></a>preprocessor:  <span class="co"># FormatConverter</span></span>
<span id="cb2-10"><a></a>  out_tensor_name: source_video</span>
<span id="cb2-11"><a></a>  out_dtype: <span class="st">"float32"</span></span>
<span id="cb2-12"><a></a>  resize_width: <span class="dv">512</span></span>
<span id="cb2-13"><a></a>  resize_height: <span class="dv">512</span></span>
<span id="cb2-14"><a></a></span>
<span id="cb2-15"><a></a>inference:  <span class="co"># Inference</span></span>
<span id="cb2-16"><a></a>  backend: <span class="st">"trt"</span></span>
<span id="cb2-17"><a></a>  pre_processor_map:</span>
<span id="cb2-18"><a></a>    <span class="co">"byom_model"</span>: [<span class="st">"source_video"</span>]</span>
<span id="cb2-19"><a></a>  inference_map:</span>
<span id="cb2-20"><a></a>    <span class="co">"byom_model"</span>: [<span class="st">"output"</span>]</span>
<span id="cb2-21"><a></a></span>
<span id="cb2-22"><a></a>postprocessor:  <span class="co"># SegmentationPostprocessor</span></span>
<span id="cb2-23"><a></a>  in_tensor_name: output</span>
<span id="cb2-24"><a></a>  <span class="co"># network_output_type: None</span></span>
<span id="cb2-25"><a></a>  data_format: nchw</span>
<span id="cb2-26"><a></a></span>
<span id="cb2-27"><a></a>viz:  <span class="co"># Holoviz</span></span>
<span id="cb2-28"><a></a>  width: <span class="dv">854</span></span>
<span id="cb2-29"><a></a>  height: <span class="dv">480</span></span>
<span id="cb2-30"><a></a>  color_lut: [</span>
<span id="cb2-31"><a></a>    [<span class="fl">0.65</span>, <span class="fl">0.81</span>, <span class="fl">0.89</span>, <span class="fl">0.1</span>],</span>
<span id="cb2-32"><a></a>    ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="use-case-2" class="title-slide slide level1 center">
<h1>Use case</h1>
<p>Real-time AI diagnosis for endoscopic pituitary surgery</p>
</section>
<section id="endoscopic-pituitary-surgery" class="slide level2">
<h2><span class="emoji" data-emoji="medical_symbol">⚕️</span> Endoscopic Pituitary Surgery</h2>
<!-- how much of this video to you plan to show? Is you talk only 20 minutes? in which case this video would take a significant chunk out of it.
-->
<!-- the slides in this section have a lot of text, I'm not sure your audience will know what to look at -->
<iframe data-external="1" src="https://www.youtube.com/embed/EwlRdxokdGk?start=11" width="85%" height="85%" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<aside class="notes">
<p>94,961 views 20 Nov 2012 Barrow Neurological Institute Neurosurgeon Andrew S. Little, MD, demonstrates the process of removing a tumor of the pituitary gland using minimally-invasive endoscopic neurosurgery. https://www.youtube.com/watch?app=desktop&amp;v=EwlRdxokdGk</p>
<p>553,519 views 28 May 2017 The pituitary gland is located at the bottom of your brain and above the inside of your nose. Endoscopic pituitary surgery (also called transsphenoidal endoscopic surgery) is a minimally invasive surgery performed through the nose and sphenoid sinus to remove pituitary tumors. https://www.youtube.com/watch?v=lwmgNLwt_ts</p>
<p>Mao, Zhehua, Adrito Das, Mobarakol Islam, Danyal Z. Khan, Simon C. Williams, John G. Hanrahan, Anouk Borg et al.&nbsp;“PitSurgRT: real-time localization of critical anatomical structures in endoscopic pituitary surgery.” International Journal of Computer Assisted Radiology and Surgery (2024): 1-8.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-for-surgery" class="slide level2">
<h2><i class="fa-brands fa-github"></i> <code>real-time-ai-for-surgery</code></h2>
<h3 id="getting-started-docs">Getting started docs</h3>

<img data-src="figures/real-time-ai-for-surgery/getting-started.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-template"><p class="caption">
Figure&nbsp;6: Getting started documentation provide with a range of links to setup, use, run and debug application including github workflow.
</p><aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-for-surgery-1" class="slide level2">
<h2><i class="fa-brands fa-github"></i> <code>real-time-ai-for-surgery</code></h2>
<h3 id="endoscopic-pituitary-surgery-1">🏥 Endoscopic pituitary surgery</h3>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">👃 Multi-head Model</a></li><li><a href="#tabset-2-2">🌓 PhaseNet Model</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/eps-mhm.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div id="tabset-2-2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/eps-pnm.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-for-surgery-2" class="slide level2 scrollable">
<h2><i class="fa-brands fa-github"></i> <code>real-time-ai-for-surgery</code></h2>
<h3 id="endoscopic-pituitary-surgery-2">🏥 Endoscopic pituitary surgery</h3>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">🔱 Multi AI models (python)</a></li><li><a href="#tabset-3-2">🔱 Multi AI models (YAML)</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>multi-ai.py</strong></pre>
</div>
<div class="sourceCode" id="cb3" data-filename="multi-ai.py"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a></span>
<span id="cb3-2"><a></a>...</span>
<span id="cb3-3"><a></a></span>
<span id="cb3-4"><a></a>        <span class="co"># Define the workflow</span></span>
<span id="cb3-5"><a></a>        <span class="cf">if</span> is_v4l2:</span>
<span id="cb3-6"><a></a>            <span class="va">self</span>.add_flow(source, viz, {(<span class="st">"signal"</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb3-7"><a></a>            <span class="va">self</span>.add_flow(source, preprocessor_v4l2, {(<span class="st">"signal"</span>, <span class="st">"source_video"</span>)})</span>
<span id="cb3-8"><a></a>            <span class="va">self</span>.add_flow(source, preprocessor_phasenet_v4l2, {(<span class="st">"signal"</span>, <span class="st">"source_video"</span>)})</span>
<span id="cb3-9"><a></a>            <span class="cf">for</span> op <span class="kw">in</span> [preprocessor_v4l2, preprocessor_phasenet_v4l2]:</span>
<span id="cb3-10"><a></a>                <span class="va">self</span>.add_flow(op, multi_ai_inference_v4l2, {(<span class="st">""</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb3-11"><a></a>            <span class="co">### connect infereceOp to postprocessors</span></span>
<span id="cb3-12"><a></a>            <span class="va">self</span>.add_flow(</span>
<span id="cb3-13"><a></a>                multi_ai_inference_v4l2, multiheadOp, {(<span class="st">"transmitter"</span>, <span class="st">"in_tensor_postproOp"</span>)}</span>
<span id="cb3-14"><a></a>            )</span>
<span id="cb3-15"><a></a>            <span class="va">self</span>.add_flow(multi_ai_inference_v4l2, segpostprocessor, {(<span class="st">"transmitter"</span>, <span class="st">""</span>)})</span>
<span id="cb3-16"><a></a>            <span class="va">self</span>.add_flow(multi_ai_inference_v4l2, phasenetOp, {(<span class="st">""</span>, <span class="st">"in"</span>)})</span>
<span id="cb3-17"><a></a></span>
<span id="cb3-18"><a></a>        <span class="cf">else</span>:</span>
<span id="cb3-19"><a></a>            <span class="va">self</span>.add_flow(source, viz, {(<span class="st">""</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb3-20"><a></a>            <span class="va">self</span>.add_flow(source, preprocessor_replayer, {(<span class="st">"output"</span>, <span class="st">"source_video"</span>)})</span>
<span id="cb3-21"><a></a>            <span class="va">self</span>.add_flow(source, preprocessor_phasenet_replayer, {(<span class="st">"output"</span>, <span class="st">"source_video"</span>)})</span>
<span id="cb3-22"><a></a>            <span class="cf">for</span> op <span class="kw">in</span> [preprocessor_replayer, preprocessor_phasenet_replayer]:</span>
<span id="cb3-23"><a></a>                <span class="va">self</span>.add_flow(op, multi_ai_inference_replayer, {(<span class="st">""</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb3-24"><a></a>            <span class="co">### connect infereceOp to postprocessors</span></span>
<span id="cb3-25"><a></a>            <span class="va">self</span>.add_flow(</span>
<span id="cb3-26"><a></a>                multi_ai_inference_replayer, multiheadOp, {(<span class="st">"transmitter"</span>, <span class="st">"in_tensor_postproOp"</span>)}</span>
<span id="cb3-27"><a></a>            )</span>
<span id="cb3-28"><a></a>            <span class="va">self</span>.add_flow(multi_ai_inference_replayer, segpostprocessor, {(<span class="st">"transmitter"</span>, <span class="st">""</span>)})</span>
<span id="cb3-29"><a></a>            <span class="va">self</span>.add_flow(multi_ai_inference_replayer, phasenetOp, {(<span class="st">""</span>, <span class="st">"in"</span>)})</span>
<span id="cb3-30"><a></a></span>
<span id="cb3-31"><a></a>        <span class="co">## connect postprocessors outputs for visualisation with holoviz</span></span>
<span id="cb3-32"><a></a>        <span class="va">self</span>.add_flow(multiheadOp, viz, {(<span class="st">"out_tensor_postproOp"</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb3-33"><a></a>        <span class="va">self</span>.add_flow(segpostprocessor, viz, {(<span class="st">""</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb3-34"><a></a>        <span class="va">self</span>.add_flow(phasenetOp, viz, {(<span class="st">"out"</span>, <span class="st">"receivers"</span>)})</span>
<span id="cb3-35"><a></a>        <span class="va">self</span>.add_flow(phasenetOp, viz, {(<span class="st">"output_specs"</span>, <span class="st">"input_specs"</span>)})</span>
<span id="cb3-36"><a></a></span>
<span id="cb3-37"><a></a>...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2">
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>multi-ai.yaml</strong></pre>
</div>
<div class="sourceCode" id="cb4" data-filename="multi-ai.yaml"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a></span>
<span id="cb4-2"><a></a>...</span>
<span id="cb4-3"><a></a></span>
<span id="cb4-4"><a></a> multi_ai_inference_v4l2:</span>
<span id="cb4-5"><a></a>  <span class="co">#</span></span>
<span id="cb4-6"><a></a>  <span class="co">#</span></span>
<span id="cb4-7"><a></a>  <span class="co"># Multi-AI Inference Operator InferenceOp()</span></span>
<span id="cb4-8"><a></a>  <span class="co">#</span></span>
<span id="cb4-9"><a></a>  <span class="co">#</span></span>
<span id="cb4-10"><a></a>  backend: <span class="st">"trt"</span></span>
<span id="cb4-11"><a></a>  pre_processor_map:</span>
<span id="cb4-12"><a></a>    <span class="co">"pit_surg_model"</span>: [<span class="st">"prepro_v4l2"</span>]</span>
<span id="cb4-13"><a></a>    <span class="co">"phasenet_model"</span>: [<span class="st">"prepro_PNv4l2"</span>]</span>
<span id="cb4-14"><a></a>  inference_map:</span>
<span id="cb4-15"><a></a>    <span class="co">"pit_surg_model"</span>: [<span class="st">"segmentation_masks"</span>, <span class="st">"landmarks"</span>]</span>
<span id="cb4-16"><a></a>    <span class="co">"phasenet_model"</span>: [<span class="st">"out"</span>]</span>
<span id="cb4-17"><a></a>  enable_fp16: <span class="va">False</span></span>
<span id="cb4-18"><a></a>  parallel_inference: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-19"><a></a>  infer_on_cpu: false <span class="co"># optional param, default to false</span></span>
<span id="cb4-20"><a></a>  input_on_cuda: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-21"><a></a>  output_on_cuda: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-22"><a></a>  transmit_on_cuda: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-23"><a></a>  is_engine_path: false <span class="co"># optional param, default to false</span></span>
<span id="cb4-24"><a></a></span>
<span id="cb4-25"><a></a>multi_ai_inference_replayer:</span>
<span id="cb4-26"><a></a>  <span class="co">#</span></span>
<span id="cb4-27"><a></a>  <span class="co">#</span></span>
<span id="cb4-28"><a></a>  <span class="co"># Multi-AI Inference Operator InferenceOp()</span></span>
<span id="cb4-29"><a></a>  <span class="co">#</span></span>
<span id="cb4-30"><a></a>  <span class="co">#</span></span>
<span id="cb4-31"><a></a>  backend: <span class="st">"trt"</span></span>
<span id="cb4-32"><a></a>  pre_processor_map:</span>
<span id="cb4-33"><a></a>    <span class="co">"pit_surg_model"</span>: [<span class="st">"prepro_replayer"</span>]</span>
<span id="cb4-34"><a></a>    <span class="co">"phasenet_model"</span>: [<span class="st">"prepro_PNreplayer"</span>]</span>
<span id="cb4-35"><a></a>  inference_map:</span>
<span id="cb4-36"><a></a>    <span class="co">"pit_surg_model"</span>: [<span class="st">"segmentation_masks"</span>, <span class="st">"landmarks"</span>]</span>
<span id="cb4-37"><a></a>    <span class="co">"phasenet_model"</span>: [<span class="st">"out"</span>]</span>
<span id="cb4-38"><a></a>  enable_fp16: <span class="va">False</span></span>
<span id="cb4-39"><a></a>  parallel_inference: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-40"><a></a>  infer_on_cpu: false <span class="co"># optional param, default to false</span></span>
<span id="cb4-41"><a></a>  input_on_cuda: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-42"><a></a>  output_on_cuda: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-43"><a></a>  transmit_on_cuda: true <span class="co"># optional param, default to true</span></span>
<span id="cb4-44"><a></a>  is_engine_path: false <span class="co"># optional param, default to false</span></span>
<span id="cb4-45"><a></a></span>
<span id="cb4-46"><a></a>...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>Speaker notes go here.</p>
<p><img data-src="figures/00_template-vector-images/drawing-v00.svg" class="quarto-figure quarto-figure-center"> ```{.python filename=“unit-test-example.py” code-line-numbers=“|30-36”}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-for-surgery-3" class="slide level2">
<h2><i class="fa-brands fa-github"></i> <code>real-time-ai-for-surgery</code></h2>
<h3 id="contributing">🤝 Contributing</h3>

<img data-src="figures/real-time-ai-for-surgery/contributing.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-template"><p class="caption">
Figure&nbsp;7: real-time-ai-for-surgery follows the Contributor Covenant Code of Conduct. Contributions, issues and feature requests are welcome.
</p><aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-for-surgery-4" class="slide level2 scrollable">
<h2><i class="fa-brands fa-github"></i> <code>real-time-ai-for-surgery</code></h2>
<h3 id="github-templates">GitHub templates</h3>
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-4-1">🎒 new users</a></li><li><a href="#tabset-4-2">🔩 new models</a></li><li><a href="#tabset-4-3"><span class="emoji" data-emoji="recycle">♻️</span> PRs</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/gh_templates_new_users.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div id="tabset-4-2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/gh_templates_new_models.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div id="tabset-4-3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/gh_templates_PRs.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>Speaker notes go here. {.scrollable}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-for-surgery-5" class="slide level2 scrollable">
<h2><i class="fa-brands fa-github"></i> <code>real-time-ai-for-surgery</code></h2>
<h3 id="release-version-summaries">Release version summaries</h3>
<div class="panel-tabset">
<ul id="tabset-5" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-5-1">v0.1.0</a></li><li><a href="#tabset-5-2">v0.2.0</a></li><li><a href="#tabset-5-3">v0.3.0</a></li><li><a href="#tabset-5-4">v0.4.0</a></li><li><a href="#tabset-5-5">v0.5.0</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/v0.1.0-rtai4s.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div id="tabset-5-2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/v0.2.0-rtai4s.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div id="tabset-5-3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/v0.3.0-rtai4s.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div id="tabset-5-4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/v0.4.0-rtai4s.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div id="tabset-5-5">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/real-time-ai-for-surgery/v0.5.0-rtai4s.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>Speaker notes go here. {.scrollable}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="use-case-3" class="title-slide slide level1 center">
<h1>Use case</h1>
<p>0cular: Open-source Care Using SOTA AI for Real-time monitoring and diagnosis</p>
</section>
<section id="ai-in-ophthalmic-imaging-modalities" class="slide level2">
<h2><span class="emoji" data-emoji="robot">🤖</span> <span class="emoji" data-emoji="eyes">👀</span> AI in ophthalmic imaging modalities</h2>

<img data-src="figures/ocular/li2023-fig2.jpg" class="quarto-figure quarto-figure-center r-stretch" id="fig-template"><p class="caption">
Figure&nbsp;8: Practical application of AI in all common ophthalmic imaging modalities
</p><div style="font-size: 40%;">
<p>Li, Zhongwen, Lei Wang, Xuefang Wu, Jiewei Jiang, Wei Qiang, He Xie, Hongjian Zhou, Shanjun Wu, Yi Shao, and Wei Chen. “Artificial intelligence in ophthalmology: The path to the real-world clinic.” Cell Reports Medicine 4, no. 7 (2023).</p>
</div>
<aside class="notes">
<p>Nystagmus {.scrollable}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="eye-movement-disorders" class="slide level2">
<h2><span class="emoji" data-emoji="robot">🤖</span> <span class="emoji" data-emoji="eyes">👀</span> Eye movement disorders</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>Nystagmus is an eye movement disorder characterized by involunatry eye oscillations.​</li>
<li>Pathologic nystagmus is estimated to be 24 per 10,000 with a slight predilection toward European ancestry [1]​.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="figures/ocular/nystagmus.gif"></p>
</div></div>
<div style="font-size: 40%;">
<p>[1] Sarvananthan, Nagini, Mylvaganam Surendran, Eryl O. Roberts, Sunila Jain, Shery Thomas, Nitant Shah, Frank A. Proudlock et al.&nbsp;“The prevalence of nystagmus: the Leicestershire nystagmus survey.” Investigative ophthalmology &amp; visual science 50, no. 11 (2009): 5201-5206.​</p>
</div>
<aside class="notes">
<p>Nystagmus {.scrollable}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-diagnosis-for-nystagmus" class="slide level2">
<h2><span class="emoji" data-emoji="robot">🤖</span> <span class="emoji" data-emoji="eyes">👀</span> Real-time AI Diagnosis for Nystagmus</h2>
<!-- ST: I like the animations here -->

<img data-src="figures/ocular/ready.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-template"><p class="caption">
Figure&nbsp;9: End-to-end workflow
</p><aside class="notes">
<p>Demo {.scrollable}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ready" class="slide level2">
<h2>🤖 👁️ READY</h2>
<p>A Python-based library for REal-time Ai Diagnosis for nYstagmus</p>
<div id="sec-hp" style="margin-top: 0px; font-size: 10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/ocular/ready-github-repo.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<p><i class="fa-brands fa-github"></i> <a href="https://github.com/0cular/ready">https://github.com/0cular/ready</a></p>
<aside class="notes">
<p>…</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-diagnosis-for-nystagmus-1" class="slide level2">
<h2><span class="emoji" data-emoji="robot">🤖</span> <span class="emoji" data-emoji="eyes">👀</span> Real-time AI Diagnosis for Nystagmus</h2>
<!-- I like the animations here -->

<img data-src="figures/ocular/animation-2024-09-13_16-45.gif" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Demo {.scrollable}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-time-ai-diagnosis-for-nystagmus-2" class="slide level2">
<h2><span class="emoji" data-emoji="robot">🤖</span> <span class="emoji" data-emoji="eyes">👀</span> Real-time AI Diagnosis for Nystagmus</h2>
<p>Future work</p>
<div class="columns">
<div class="column" style="width:50%;">
<p>Real-time AI guidance for high-quality images (Liu et al.&nbsp;2023) <img data-src="figures/ocular/liu_2023_graphical_abstract.jpg" class="quarto-figure quarto-figure-center" style="width:50.0%"></p>
</div><div class="column" style="width:50%;">
<p>Implement UNET-Visual Transformer models (Yao et al.&nbsp;2022)<br>
<img data-src="figures/ocular/yao2022_fig1.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
<p><i class="fa-brands fa-github"></i> <a href="https://github.com/0cular/unetvit4sclera">github.com/0cular/unetvit4sclera</a></p>
</div></div>
<div style="font-size: 40%;">
<p>Liu, L., Wu, X., Lin, D., Zhao, L., Li, M., Yun, D., Lin, Z., Pang, J., Li, L., Wu, Y. and Lai, W., 2023. DeepFundus: a flow-cytometry-like image quality classifier for boosting the whole life cycle of medical artificial intelligence. Cell Reports Medicine, 4(2).</p>
<p>Yao, Chang, Menghan Hu, Qingli Li, Guangtao Zhai, and Xiao-Ping Zhang. “Transclaw u-net: claw u-net with transformers for medical image segmentation.” In 2022 5th International Conference on Information Communication and Signal Processing (ICICSP), pp.&nbsp;280-284. IEEE, 2022.</p>
</div>
<aside class="notes">
<p>Plans {.scrollable}</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="sec-ossh" class="title-slide slide level1 center">
<h1>Open-Source Software in Healthcare</h1>

</section>
<section id="section-1" class="slide level2" data-background-image="figures/oss4surgmedaitech/oss4st-hsmr24-p00.svg" data-background-size="cover">
<h2></h2>
<div class="footer">
<p><a href="https://github.com/oss-for-surgtech/workshop-hamlyn2024"><i class="fa-brands fa-github"></i> https://github.com/oss-for-surgtech/workshop-hamlyn2024</a></p>
</div>
</section>
<section id="healing-through-collaboration" class="slide level2">
<h2>Healing Through Collaboration</h2>
<!-- Open-Source Software in Surgical, Biomedical and AI Technologies -->
<div id="sec-mt" style="margin-top: 0px; font-size: 50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/oss4surgmedaitech/open-source-for-smait.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<aside class="notes">
<p>https://github.com/openregulatory/templates</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="sec-ta" class="title-slide slide level1 center">
<h1>Key Takeaways</h1>
<div class="fragment">
<ul>
<li><span class="emoji" data-emoji="wrench">🔧</span> <span class="emoji" data-emoji="hospital">🏥</span> Challenges in translating research from bench to bedside.</li>
<li><span class="emoji" data-emoji="robot">🤖</span> <span class="emoji" data-emoji="recycle">♻️</span> Use cases for synthetic data and real-time AI-driven diagnosis.</li>
</ul>
</div>
<div class="fragment">
<p>How to shape the future of Healthcare using Open-Source Software!!!*</p>
</div>
<div class="fragment">
<ul>
<li><span class="emoji" data-emoji="school_satchel">🎒</span> Contribute to the creation of high-quality educational and training materials.</li>
<li><i class="fa-brands fa-github"></i> Release open-source code, data, and models in alignment with quality standards.</li>
</ul>
</div>
</section>
<section id="acknowledgements" class="slide level2">
<h2>🙌 Acknowledgements</h2>
<ul>
<li>Diego Kaski
<ul>
<li>UCL Queen Square Institute of Neurology</li>
</ul></li>
<li>Zhehua Mao, Sophia Bano and Matt Clarkson
<ul>
<li>Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS) at UCL</li>
</ul></li>
<li>Mikael Brudfors and Nadim Daher
<ul>
<li>NVIDIA Healthcare AI</li>
</ul></li>
<li>Steve Thompson et al.
<ul>
<li>Advanced Research Computing Centre (ARC) at UCL</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="additional-slides" class="title-slide slide level1 center">
<h1>Additional slides</h1>

</section>
<section id="the-first-regulatory-clearance-of-an-open-source-automated-insulin-delivery-algorithm" class="slide level2">
<h2>The First Regulatory Clearance of an Open-Source Automated Insulin Delivery Algorithm</h2>
<ul>
<li>In 2018, Tidepool launched the Tidepool Loop initiative to generate real-world evidence and seek regulatory clearance for Loop.</li>
<li>By late 2020, Tidepool submitted an application to the FDA for an interoperable automated glycemic controller (iAGC) based on Loop.</li>
<li>After 2 years, the FDA approved the Tidepool Loop iAGC on January 23, 2023.</li>
</ul>
<div style="font-size: 40%;">
<p>Braune, Katarina, Sufyan Hussain, and Rayhan Lal. “The first regulatory clearance of an open-source automated insulin delivery algorithm.” Journal of Diabetes Science and Technology 17, no. 5 (2023): 1139-1141. <a href="https://journals.sagepub.com/doi/10.1177/19322968231164166">DOI</a> <a href="https://scholar.google.com/scholar?cites=11792880181049903500&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Citations</a></p>
<p><a href="https://www.tidepool.org/open">https://www.tidepool.org/open</a></p>
<p><a href="https://github.com/tidepool-org">https://github.com/tidepool-org</a></p>
<p><a href="https://github.com/LoopKit">https://github.com/LoopKit</a></p>
</div>
<aside class="notes">
<ul>
<li>Food and Drug Administration (FDA</li>
<li>The #WeAreNotWaiting diabetes movement continues demanding safety and innovation at a faster pace than industry and regulators can currently offer. {.scrollable}</li>
<li>Other examples Reimagining Public Healthcare with AI https://ohc.network/</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="fda-approved-ai-based-medical-devices" class="slide level2">
<h2>FDA-approved AI-based Medical Devices</h2>
<!-- ST I find the 7 slides in this section very difficult to follow. It should be better when you're talking to them, but just reading them I'm not sure what you're trying to communicate -->
<div style="margin-top: 0px; font-size: 50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/regulation-innovation/fda-approved-ai-based-med-devs.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div style="font-size: 40%;">
<p>Benjamens, S., Dhunnoo, P. and Meskó, B. The state of artificial intelligence-based FDA-approved medical devices and algorithms: an online database. npj Digit. Med. 3, 118 (2020).</p>
</div>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="favicon.svg" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 720,

        // Factor of the display size that should remain empty around the content
        margin: 2.5e-2,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/mxochicale\.github\.io\/open-healthcare-slides\/");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>